---
title: "Activity - Linear Systems"
author: "Solutions"
output: html_document
---

\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\mat}[1]{\mathbf{#1}}

### Objectives

* Review key ideas of systems of linear equations
* Investigate algorithmic complexity
* Solidify conceptual understanding of conditioning
* Apply idea of conditioning to matrix problems

### Procedure

* Please collaborate on this activity with one person as scribe (typist). There should only be one laptop open. We're aiming for actual collaboration here, not two or three people working in parallel.

* It doesn't matter if you finish the whole activity during class.

* It **does** mater if you focus on helping each other learn. Helping each other learn is the point of this activity. Completing the problems is merely a mechanism to guide you towards learning.

* It **does** mater if everyone participates. The expectation is that every group member participates, where the definition of "participation" can include asking questions, answering questions, brainstorming, or any other form of meaningful engagement.

* In the last three minutes of class, before you leave, please knit your .Rmd file to html, print the html to .pdf, and have the scribe submit it as a group assignment through GLOW.

* Don't forget that the solutions are available on GLOW.

### Problem 0

Recalling that academic integrity policies apply even in an ungraded course, please disclose any irregular circumstances related to participation in your group (for instance, a group member was missing and did not contribute to this document).

### Problem 0 Solution

Your solution goes here.

### Problem 1

Which of the following sets of vectors are bases for $\mathbb{R}^2$?

a. $\{(0, 1), (1, 1)\}$
b. $\{(1, 0), (0, 1), (1, 1)\}$
c. $\{(1, 0), (−1, 0\}$
d. $\{(1, 1), (1, −1)\}$
e. $\{((1, 1), (2, 2)\}$
f. $\{(1, 2)\}$

### Problem 1 solution

a. Yes, because there are two vectors and they are linearly independent.
b. No, because there are three vectors, so they cannot be linearly independent.
c. No, because the vectors are linearly dependent.
d. Yes, because there are two vectors and they are linearly independent.
e. No, because the vectors are linearly dependent.
f. No, because there is only one vector.

### Problem 2

What is the dimension of the intersection of the following two planes in $\mathbb{R}^3$?
$$x + 2y − z = 0, \quad 3x − 3y + z = 0$$

### Problem 2 Solution

Since there are two planes and they are not parallel, the intersection must be a line, so the dimension is 1.

### Problem 3

Solve (by hand) the system below.

$$
\begin{pmatrix}1 & 2 & 0 \\ 3 & 2 & 4 \\ -2 & 1 & -2 \end{pmatrix} \begin{pmatrix} x \\ y \\ z \end{pmatrix} = \begin{pmatrix} 1 \\ 7\\ -1 \end{pmatrix}
$$

### Problem 3 Solution
$$x = -1,\ y = 1,\ z = 2$$

### Problem 4

Put the augmented coefficient matrix for the system of equations
$$
\begin{aligned}
x+y+z&=2\\
x+3y+3z&=0\\
x+3y+6z&=3
\end{aligned}
$$
into row echelon form.

### Problem 4 Solution

$$
\begin{pmatrix}
1 & 1 & 1 & 2 \\
0 & 2 & 2 & -2 \\
0 & 0 & 3 & 3
\end{pmatrix}
$$

### Problem 5

I've written a function called `eliminate` that performs Gaussian elimination in order to transform a matrix to row echelon form.

```{r}
eliminate <- function(A,tol=10^-8) {
  n = nrow(A)
  for ( j in 1:(n-1) ) {
    pivot = A[j,j]
    if (abs(pivot) < tol) stop('zero pivot encountered')
    for ( i in (j+1):n ) {
      A[i,] = A[i,] - A[i,j]/pivot * A[j,]
    }
  }
  return(A)
}
```

Demonstrate $\mathcal{O}(n^3)$ complexity by doing the following. Run the `eliminate` command on an $n \times n$ random matrix for each of $n=270,\ 540,\ 810,\ 1080,\ 1350$, saving the run time for each value of $n$. Then, use the `lm` command to fit a line to the points $(\log n,\log t)$ and find the slope.

### Problem 5 solution

```{r cache = TRUE}
set.seed(12345)
nvals <- 3*(1:5)*90
t <- NULL
for (n in nvals) {
  A <- matrix(runif(n^2), ncol = n)
  t <- c(t, system.time(eliminate(A))[3])
}
lm(log(t)~log(nvals))
```

### Problem 6

Compute by hand the eigenvalues of the matrices 
$$\mat{A}=\begin{pmatrix} 1 & 1000 \\ 0 & 1\end{pmatrix}, \qquad \widetilde{\mat{A}}=\begin{pmatrix} 1 & 1000 \\ 0.001 & 1\end{pmatrix}.$$
Would you say that the problem of computing eigenvalues is well-conditioned or ill-conditioned? Check the condition number of $\mat{A}$ using the `kappa` command. For concreteness, use the 2-norm, though there is nothing special about that choice.

### Problem 6 Solution

The eigenvalues of $\mat{A}$ are 1 and 1, but the eigenvalues of $\widetilde{\mat{A}}$ are 0 and 2. So changing the problem data by only a small amount (the backward error) results in a larger change in the problem solution (the forward error). Thus, the forward error divided by the backward error is quite large. Since the condition number is an upper bound on this ratio, it must also be large, and the problem is ill-conditioned.

```{r}
A <- matrix(c(1,1000,0,1), byrow = TRUE, nrow = 2)
kappa(A, norm = "2", exact = TRUE)
```